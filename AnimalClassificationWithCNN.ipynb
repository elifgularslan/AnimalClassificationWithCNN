{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8C6pUGQMhq2FQC065lddH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elifgularslan/AnimalClassificationWithCNN/blob/main/AnimalClassificationWithCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Xsdm9n_LGU"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â˜ï¸ 0. Dataset Download & Setup (Veri Seti Ä°ndirme ve Kurulum)\n",
        "\n",
        "**English:**\n",
        "In this step, we fetch the **Animals-10** dataset directly from Kaggle into the Google Colab environment.\n",
        "* **Kaggle API:** We use the `!kaggle datasets download` command to pull the dataset quickly without manual uploading.\n",
        "* **Unzip:** The dataset comes in a compressed `.zip` format. We use `!unzip` to extract the images into a specific folder named `animals10` for easy access.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "Bu adÄ±mda, **Animals-10** veri setini doÄŸrudan Kaggle Ã¼zerinden Google Colab ortamÄ±na Ã§ekiyoruz.\n",
        "* **Kaggle API:** Veri setini elle yÃ¼klemekle uÄŸraÅŸmadan, hÄ±zlÄ±ca indirmek iÃ§in `!kaggle datasets download` komutunu kullanÄ±yoruz.\n",
        "* **Unzip (Zip'ten Ã‡Ä±karma):** Veri seti sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ `.zip` formatÄ±nda gelir. Resimleri eriÅŸilebilir hale getirmek ve dÃ¼zenli tutmak iÃ§in `!unzip` komutuyla `animals10` klasÃ¶rÃ¼ne Ã§Ä±kartÄ±yoruz."
      ],
      "metadata": {
        "id": "67hc5j1R5Q9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d alessiocorrado99/animals10\n",
        "!unzip animals10.zip -d animals10"
      ],
      "metadata": {
        "id": "fe7DaBeX_eC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ðŸ“š 1. Libraries & Setup (KÃ¼tÃ¼phaneler ve Kurulum)\n",
        "\n",
        "**English:**\n",
        "In this section, we import the necessary libraries.\n",
        "* **TensorFlow & Keras:** The core deep learning framework used to build and train the model.\n",
        "* **Matplotlib:** Used for visualizing the data, training graphs (accuracy/loss), and prediction results.\n",
        "* **OpenCV (cv2):** Used for advanced image processing, specifically for reading images from disk and converting color spaces (BGR to RGB).\n",
        "* **Numpy:** Fundamental package for scientific computing and array manipulation.\n",
        "* **GC (Garbage Collector):** Used to manually clean up RAM to prevent session crashes in Google Colab.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "Bu bÃ¶lÃ¼mde gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±yoruz.\n",
        "* **TensorFlow & Keras:** Modeli kurmak ve eÄŸitmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z temel derin Ã¶ÄŸrenme Ã§atÄ±sÄ±.\n",
        "* **Matplotlib:** Veriyi, eÄŸitim grafiklerini (doÄŸruluk/kayÄ±p) ve tahmin sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirmek iÃ§in kullanÄ±lÄ±r.\n",
        "* **OpenCV (cv2):** GeliÅŸmiÅŸ gÃ¶rÃ¼ntÃ¼ iÅŸleme iÃ§in kullanÄ±lÄ±r; Ã¶zellikle diskten resim okuma ve renk uzayÄ± dÃ¶nÃ¼ÅŸÃ¼mleri (BGR'den RGB'ye) yapmak iÃ§in gereklidir.\n",
        "* **Numpy:** Bilimsel hesaplamalar ve dizi (array) iÅŸlemleri iÃ§in temel paket.\n",
        "* **GC (Ã‡Ã¶p ToplayÄ±cÄ±):** Google Colab'de oturum Ã§Ã¶kmesini Ã¶nlemek amacÄ±yla RAM'i manuel olarak temizlemek iÃ§in kullanÄ±lÄ±r"
      ],
      "metadata": {
        "id": "10MuHtGO3IL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling\n",
        "from tensorflow.keras.layers import RandomRotation, RandomZoom, RandomFlip, RandomContrast, GaussianNoise\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gc # garbage collector\n",
        "\n",
        "# TR: RAM ÅŸiÅŸmesini Ã¶nlemek iÃ§in Ã§Ã¶p toplayÄ±cÄ±yÄ± Ã§alÄ±ÅŸtÄ±rÄ±yoruz.\n",
        "# EN: Running garbage collector to prevent RAM overflow.\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n"
      ],
      "metadata": {
        "id": "ftWVMZEG3r6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“¥ 2. Data Loading & Preprocessing (Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme)\n",
        "\n",
        "**English:**\n",
        "We load the **Animals-10** dataset using `image_dataset_from_directory`.\n",
        "* **Image Size:** We resize all images to `224x224` pixels to match standard CNN input requirements.\n",
        "* **Split:** The data is split into **Training (80%)** and **Validation (20%)** sets.\n",
        "* **Optimization:** We use `prefetch` instead of `cache` to stream data efficiently without overloading the RAM.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "**Animals-10** veri setini `image_dataset_from_directory` fonksiyonu ile yÃ¼klÃ¼yoruz.\n",
        "* **GÃ¶rÃ¼ntÃ¼ Boyutu:** Standart CNN giriÅŸ gereksinimlerine uymasÄ± iÃ§in tÃ¼m resimleri `224x224` piksel boyutuna getiriyoruz.\n",
        "* **AyÄ±rma:** Veri seti **EÄŸitim (%80)** ve **DoÄŸrulama (%20)** olarak ikiye ayrÄ±ldÄ±.\n",
        "* **Optimizasyon:** RAM'i ÅŸiÅŸirmeden veriyi verimli bir ÅŸekilde akÄ±tmak iÃ§in `cache` yerine `prefetch` yÃ¶ntemini kullanÄ±yoruz."
      ],
      "metadata": {
        "id": "XrWzuJ2U3jv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/animals10/raw-img\"\n",
        "\n",
        "# TR: Resim boyutu. Model 224x224 piksel bekler.\n",
        "# EN: Image size. The model expects 224x224 pixels.\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# TR: Bir seferde iÅŸlenen resim sayÄ±sÄ±.\n",
        "# EN: Number of images processed at once\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "print(\"Does the folder exist?\", os.path.exists(data_dir))\n",
        "print(\"Contents:\", os.listdir(data_dir))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TR: EÄŸitim veri setini oluÅŸturuyoruz (%80)\n",
        " # EN: Creating the training dataset (80%)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,    # TR: Verinin %20'sini test iÃ§in ayÄ±r. / EN: Split 20% for validation.\n",
        "    subset=\"training\",       # TR: Bu kÄ±sÄ±m eÄŸitim iÃ§in. / EN: This subset is for training.\n",
        "    seed=42,                 # TR: Rastgelelik sabiti (her seferinde aynÄ± ayrÄ±mÄ± yapar). / EN: Random seed for reproducibility.\n",
        "    label_mode='int',        # TR: Etiketler tamsayÄ± (0, 1, 2...) olarak gelir. / EN: Labels are returned as integers.\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "# TR: DoÄŸrulama (Test) veri setini oluÅŸturuyoruz (%20)\n",
        "    # EN: Creating the validation dataset (20%)\n",
        "\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    label_mode='int',\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes ({num_classes} total):\", class_names)\n",
        "\n",
        "\n",
        "# TR: Performans ayarÄ±. Veriyi Ã¶nbelleÄŸe almadan (cache yok) sÄ±radaki veriyi hazÄ±rlar.\n",
        "# EN: Performance tuning. Prefetches the next batch without caching (saves RAM)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0Mx5NOjj_t-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ” 3. Exploratory Data Analysis (KeÅŸifÃ§i Veri Analizi)\n",
        "\n",
        "**English:**\n",
        "Before training, it is crucial to visualize the dataset to ensure data integrity.\n",
        "In this block, we randomly select and display one sample image from each of the 10 classes. This helps us verify that the labels are correct and the images are loaded properly.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "EÄŸitime baÅŸlamadan Ã¶nce, veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ doÄŸrulamak iÃ§in veri setini gÃ¶rselleÅŸtirmek Ã§ok Ã¶nemlidir.\n",
        "Bu blokta, 10 sÄ±nÄ±fÄ±n her birinden rastgele birer Ã¶rnek seÃ§ip ekrana basÄ±yoruz. Bu iÅŸlem, etiketlerin doÄŸruluÄŸunu ve resimlerin dÃ¼zgÃ¼n yÃ¼klendiÄŸini teyit etmemizi saÄŸlar."
      ],
      "metadata": {
        "id": "0Lu1XKHy4McR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 3. DATA EXPLORATION (VERÄ° KEÅžFÄ°)\n",
        "# ==========================================\n",
        "# TR: Her sÄ±nÄ±ftan rastgele bir Ã¶rnek gÃ¶stererek veri setini tanÄ±yalÄ±m.\n",
        "# EN: Let's explore the dataset by showing one random sample from each class.\n",
        "\n",
        "\n",
        "data_dir = \"/content/animals10/raw-img\"\n",
        "\n",
        "# TR: TÃ¼m sÄ±nÄ±flarÄ± bul ve sÄ±rala\n",
        "# EN: Find and sort class directories\n",
        "classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "classes.sort()\n",
        "\n",
        "print(f\"Number of classes: {len(classes)}\")\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# TR: 10 SÄ±nÄ±f iÃ§in 2 satÄ±r 5 sÃ¼tunluk tablo ayarla\n",
        "# EN: Set up a table with 2 rows and 5 columns for the 10 classes\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "    # TR:KlasÃ¶rdeki tÃ¼m resimleri listele\n",
        "    # EN: List valid image files in the directory.\n",
        "    files = [f for f in os.listdir(class_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "\n",
        "    # TR: Rastgele bir dosya seÃ§. / EN: Pick a random file.\n",
        "    if len(files) > 0:\n",
        "        random_file = random.choice(files)\n",
        "        img_path = os.path.join(class_path, random_file)\n",
        "\n",
        "        # Resmi oku ve renklendir\n",
        "        # Read and color the image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Tabloya yerleÅŸtir (i+1 Ã§Ã¼nkÃ¼ subplot 1'den baÅŸlar)\n",
        "        # Place into the table (i+1 because subplot starts from 1)\n",
        "\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_name.capitalize(), fontsize=12, fontweight='bold') # TR:BaÅŸlÄ±k (Kedi, KÃ¶pek vs.) # EN:Title (Cat, Dog etc.)\n",
        "        plt.axis(\"off\") # TR:Ã‡erÃ§eveyi kaldÄ±r # EN:Remove frame\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Random Samples from Animals-10 Dataset\", fontsize=16, y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "246keQoT_4Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ§  4. Model Architecture (Model Mimarisi)\n",
        "\n",
        "**English:**\n",
        "We are building a **Custom CNN (Convolutional Neural Network)** from scratch.\n",
        "* **Robustness:** We add `GaussianNoise` and Data Augmentation (Flip, Rotation, Zoom) layers to make the model resistant to image noise and prevent overfitting.\n",
        "* **Rescaling:** Normalizes pixel values from `0-255` to `0-1` range for faster convergence.\n",
        "* **Feature Extraction:** We use 3 blocks of `Conv2D` (Convolution) and `MaxPooling2D` layers to detect edges, textures, and shapes.\n",
        "* **Classifier:** A fully connected `Dense` layer with `Dropout(0.3)` is used to classify the features into 10 categories.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "SÄ±fÄ±rdan (from scratch) bir **Ã–zel CNN (EvriÅŸimli Sinir AÄŸÄ±)** inÅŸa ediyoruz.\n",
        "* **DayanÄ±klÄ±lÄ±k (Robustness):** Modeli gÃ¶rÃ¼ntÃ¼ gÃ¼rÃ¼ltÃ¼sÃ¼ne karÅŸÄ± direnÃ§li hale getirmek ve aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nlemek iÃ§in `GaussianNoise` ve Veri ArtÄ±rma (Ã‡evirme, DÃ¶ndÃ¼rme, YakÄ±nlaÅŸtÄ±rma) katmanlarÄ± ekliyoruz.\n",
        "* **Ã–lÃ§eklendirme:** Piksel deÄŸerlerini `0-255` aralÄ±ÄŸÄ±ndan `0-1` aralÄ±ÄŸÄ±na Ã§ekerek eÄŸitimin daha hÄ±zlÄ± yakÄ±nsamasÄ±nÄ± saÄŸlar.\n",
        "* **Ã–zellik Ã‡Ä±karÄ±mÄ±:** KenarlarÄ±, dokularÄ± ve ÅŸekilleri algÄ±lamak iÃ§in 3 bloklu `Conv2D` ve `MaxPooling2D` katmanlarÄ± kullanÄ±yoruz.\n",
        "* **SÄ±nÄ±flandÄ±rÄ±cÄ±:** Ã–zellikleri 10 kategoriye ayÄ±rmak iÃ§in `Dropout(0.3)` iÃ§eren tam baÄŸlantÄ±lÄ± bir `Dense` katman kullanÄ±yoruz."
      ],
      "metadata": {
        "id": "hAC4JVSl4TWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. MODEL ARCHITECTURE (MODEL MÄ°MARÄ°SÄ°)\n",
        "# ==========================================\n",
        "\n",
        "# TR: Veri ArtÄ±rma KatmanÄ±. Ezberlemeyi Ã¶nlemek iÃ§in resimleri deÄŸiÅŸtirir.\n",
        "# EN: Data Augmentation Layer. Modifies images to prevent overfitting.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),   # TR: Yatay Ã§evir / EN: Horizontal flip\n",
        "    layers.RandomRotation(0.1),        # TR:%10 DÃ¶ndÃ¼r / EN: Rotate 10%\n",
        "    layers.RandomZoom(0.1),            # TR: %10 YakÄ±nlaÅŸtÄ±r / EN: Zoom 10%\n",
        "    layers.RandomContrast(0.2),        # TR: Kontrast deÄŸiÅŸtir / EN: Adjust contrast\n",
        "    layers.RandomBrightness(0.2),\n",
        "    layers.GaussianNoise(0.02),        # TR: Hafif gÃ¼rÃ¼ltÃ¼ ekle / EN: Add slight noise\n",
        "], name=\"augmentation_layer\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lQK80X2f_1kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# TR: Ã–nce veri artÄ±rmayÄ± uygula. / EN: Apply data augmentation first.\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "# TR: Normalizasyon. Piksel deÄŸerlerini 0-255 arasÄ±ndan 0-1 arasÄ±na Ã§eker.\n",
        "# EN: Normalization. Scales pixel values from 0-255 to 0-1 range.\n",
        "x = layers.Rescaling(1/255)(x)\n",
        "\n",
        "# --- CNN BLOCKS (CNN BLOKLARI) ---\n",
        "# TR: Ã–zellik Ã‡Ä±karma (Kenarlar, ÅŸekiller vb.)\n",
        "# EN: Feature Extraction (Edges, shapes, etc.)\n",
        "\n",
        "# Block 1\n",
        "x = layers.Conv2D(32, 3, padding='same', activation='relu')(x) # 32 Filters\n",
        "x = layers.MaxPooling2D()(x)    # TR: Boyutu yarÄ±ya indir / EN: Reduce size by half\n",
        "\n",
        "# Block 2\n",
        "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "\n",
        "# Block 3\n",
        "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "\n",
        "\n",
        "# --- CLASSIFICATION  (SINIFLANDIRMA ) ---\n",
        "x = layers.Flatten()(x)# TR: DÃ¼z vektÃ¶re Ã§evir / EN: Flatten to vector\n",
        "\n",
        "# TR: Tam BaÄŸlantÄ±lÄ± Katman / EN: Fully Connected Layer\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "# TR: Unutma KatmanÄ±. NÃ¶ronlarÄ±n %30'sini rastgele kapatÄ±r (Overfitting Ã¶nlemi).\n",
        "# EN: Dropout Layer. Randomly turns off 30% of neurons (Prevents overfitting).\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "# TR: Ã‡Ä±kÄ±ÅŸ KatmanÄ±. Her sÄ±nÄ±f iÃ§in bir olasÄ±lÄ±k Ã¼retir.\n",
        "# EN: Output Layer. Produces a probability for each class.\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "# TR: Modeli birleÅŸtir ve derle.\n",
        "# EN: Construct and compile the model.\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "uGTpOgLW__uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸš€ 5. Training with Callbacks (Callback ile EÄŸitim)\n",
        "\n",
        "**English:**\n",
        "To optimize the training process, we use intelligent callbacks:\n",
        "* **EarlyStopping:** Monitors `val_loss`. If the model stops improving for 5 epochs, training is stopped automatically to save time and prevent overfitting. It restores the best weights found.\n",
        "* **ReduceLROnPlateau:** Monitors `val_loss`. If the loss plateaus (stops decreasing), it reduces the learning rate by a factor of `0.2` to allow fine-tuning.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "EÄŸitim sÃ¼recini optimize etmek iÃ§in akÄ±llÄ± \"geri Ã§aÄŸÄ±rma\" (callback) mekanizmalarÄ± kullanÄ±yoruz:\n",
        "* **EarlyStopping (Erken Durdurma):** `val_loss` deÄŸerini izler. EÄŸer model 5 epoch boyunca geliÅŸmezse, zaman kazanmak ve aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in eÄŸitimi otomatik olarak durdurur. Bulunan en iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kler.\n",
        "* **ReduceLROnPlateau:** `val_loss` deÄŸerini izler. EÄŸer kayÄ±p deÄŸeri sabitlenirse (dÃ¼ÅŸmeyi bÄ±rakÄ±rsa), Ã¶ÄŸrenme hÄ±zÄ±nÄ± `0.2` kat dÃ¼ÅŸÃ¼rerek modelin daha hassas Ã¶ÄŸrenmesini (fine-tuning) saÄŸlar."
      ],
      "metadata": {
        "id": "aHy4_9lU4fsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. CALLBACKS (GERÄ° Ã‡AÄžIRMALAR)\n",
        "# ==========================================\n",
        "\n",
        "\n",
        "# TR: Erken Durdurma. EÄŸer model geliÅŸmeyi durdurursa eÄŸitimi keser.\n",
        "# EN: Early Stopping. Stops training if the model stops improving.\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',       # Test hatasÄ±nÄ± takip et # Track validation loss\n",
        "    patience=5,               # 5 epoch boyunca iyileÅŸme olmazsa dur# Stop if no improvement for 5 epochs\n",
        "    restore_best_weights=True,# En iyi sonucu hafÄ±zada tut (Ã‡OK Ã–NEMLÄ°)# Keep the best model weights (VERY IMPORTANT)\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TR: Ã–ÄŸrenme HÄ±zÄ± AzaltÄ±cÄ±. Model tÄ±kanÄ±rsa adÄ±mlarÄ± kÃ¼Ã§Ã¼ltÃ¼r.\n",
        "# EN: Learning Rate Reducer. Reduces step size if model gets stuck.\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,               # TÄ±kanÄ±rsa hÄ±zÄ± 5 kat dÃ¼ÅŸÃ¼r  # If plateau, reduce learning rate by 5x\n",
        "    patience=2,               # 2 epoch sabret, dÃ¼zelmezse hÄ±zÄ± dÃ¼ÅŸÃ¼r # Wait 2 epochs, then reduce LR if no improvement\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 6. TRAINING (EÄžÄ°TÄ°M)\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n Starting Training...\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=25,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 7. VISUALIZATION & SAVING (GÃ–RSELLEÅžTÄ°RME VE KAYIT)\n",
        "# ==========================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "\n",
        "# DoÄŸruluk GrafiÄŸi # Accuracy Plot\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(acc, label=\"Train Accuracy\")\n",
        "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# KayÄ±p GrafiÄŸi  # Loss Plot\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(loss, label=\"Train Loss\")\n",
        "plt.plot(val_loss, label=\"Validation Loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# TR: Modeli kaydet / EN: Save the model\n",
        "model_name = \"animals10_Model.keras\"\n",
        "model.save(model_name)\n",
        "print(f\"Model saved successfully: {model_name}\")"
      ],
      "metadata": {
        "id": "vdmbpNKBU--C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Š 6. Evaluation & Prediction (DeÄŸerlendirme ve Tahmin)\n",
        "\n",
        "**English:**\n",
        "In the final step, we evaluate the model's performance:\n",
        "* **Learning Curves:** We plot Accuracy and Loss graphs to analyze the training progress and check for overfitting/underfitting.\n",
        "* **Testing:** We select a random image from the validation set that the model has never seen before and perform a prediction to visualize the result in real-time.\n",
        "\n",
        "**TÃ¼rkÃ§e:**\n",
        "Son adÄ±mda, modelin performansÄ±nÄ± deÄŸerlendiriyoruz:\n",
        "* **Ã–ÄŸrenme EÄŸrileri:** EÄŸitimin ilerleyiÅŸini analiz etmek ve aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) durumunu kontrol etmek iÃ§in DoÄŸruluk (Accuracy) ve KayÄ±p (Loss) grafiklerini Ã§izdiriyoruz.\n",
        "* **Test Etme:** DoÄŸrulama setinden, modelin daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi rastgele bir resim seÃ§iyoruz ve sonucu gerÃ§ek zamanlÄ± olarak gÃ¶rmek iÃ§in bir tahmin gerÃ§ekleÅŸtiriyoruz."
      ],
      "metadata": {
        "id": "8LJl8ok_4p4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 8. PREDICTION TEST (TAHMÄ°N TESTÄ°)\n",
        "# ==========================================\n",
        "print(\"\\n Testing with a Random Image...\")\n",
        "\n",
        "def predict_image_corrected(path):\n",
        "   # TR: Resmi yÃ¼kle ve modelin anlayacaÄŸÄ± boyuta (224x224) getir.\n",
        "    # EN: Load the image and resize to target size (224x224).\n",
        "    img = tf.keras.utils.load_img(path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "       # TR: Resmi diziye (array) Ã§evir.\n",
        "    # EN: Convert image to array.\n",
        "    arr = tf.keras.utils.img_to_array(img)\n",
        "\n",
        "    # TR: Batch boyutu ekle (Model tek resim deÄŸil, resim grubu bekler).\n",
        "    # EN: Add batch dimension (Model expects a batch, not a single image).\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "\n",
        "    # TR: Tahmin yap.\n",
        "    # EN: Make prediction.\n",
        "    pred = model.predict(arr)[0]\n",
        "    idx = np.argmax(pred)\n",
        "    prob = pred[idx]\n",
        "\n",
        "\n",
        "    # TR: GerÃ§ek sÄ±nÄ±f ismini dosya yolundan al (DÃœZELTÄ°LEN KISIM BURASI)\n",
        "    # EN: Get actual class name from file path (FIXED HERE)\n",
        "    # random_path yerine path kullanÄ±yoruz!\n",
        "    actual_class = path.split('/')[-2]\n",
        "\n",
        "    # TR: Sonucu GÃ¶ster.\n",
        "    # EN: Show Result.\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # TR: BaÅŸlÄ±k: GerÃ§ek SÄ±nÄ±f vs Tahmin Edilen SÄ±nÄ±f\n",
        "    # EN: Title: Actual Class vs Predicted Class\n",
        "    plt.title(f\"Actual: {actual_class}\\nPredicted: {class_names[idx]} ({prob*100:.2f}%)\")\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# --- MAIN EXECUTION (ANA Ã‡ALIÅžTIRMA) ---\n",
        "\n",
        "import glob\n",
        "\n",
        "val_dir = \"/content/animals10/raw-img\"\n",
        "\n",
        " # TR: KlasÃ¶rdeki tÃ¼m resim formatlarÄ±nÄ± (.jpg, .png, .jpeg) bul.\n",
        "# EN: Find all image formats (.jpg, .png, .jpeg) in the directory.\n",
        "all_images = glob.glob(val_dir + \"/*/*.jpg\") + glob.glob(val_dir + \"/*/*.jpeg\") + glob.glob(val_dir + \"/*/*.png\")\n",
        "\n",
        "if len(all_images) > 0:\n",
        "    # TR: Rastgele bir resim seÃ§.\n",
        "    # EN: Choose a random image.\n",
        "    random_image_path = random.choice(all_images)\n",
        "    print(f\"Selected Image :{random_image_path}\")\n",
        "\n",
        "    # TR: Fonksiyonu Ã§aÄŸÄ±r.\n",
        "    # EN: Call the function.\n",
        "    predict_image_corrected(random_image_path)\n",
        "else:\n",
        "    print(\" No images found! (Resim bulunamadÄ±!\")"
      ],
      "metadata": {
        "id": "faD2NZ01AN06"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}